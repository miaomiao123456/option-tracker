"""
PostgreSQL æ•°æ®å¯¼å…¥è„šæœ¬
ä» JSON æ–‡ä»¶å¯¼å…¥æ•°æ®åˆ° PostgreSQL
"""
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import json
from pathlib import Path
import logging
from datetime import datetime
from sqlalchemy import create_engine, text, MetaData, inspect
from sqlalchemy.orm import sessionmaker

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def parse_datetime(value):
    """è§£ææ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²"""
    if not value:
        return None
    try:
        # å°è¯•è§£æ ISO æ ¼å¼
        return datetime.fromisoformat(value)
    except:
        return value


def import_json_to_postgresql(json_file: str, pg_connection_string: str):
    """
    ä» JSON æ–‡ä»¶å¯¼å…¥æ•°æ®åˆ° PostgreSQL

    Args:
        json_file: JSON æ•°æ®æ–‡ä»¶è·¯å¾„
        pg_connection_string: PostgreSQL è¿æ¥å­—ç¬¦ä¸²
    """
    logger.info("=" * 60)
    logger.info("å¼€å§‹å¯¼å…¥æ•°æ®åˆ° PostgreSQL")
    logger.info("=" * 60)

    # æ£€æŸ¥ JSON æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(json_file):
        logger.error(f"âŒ JSON æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
        return False

    # è¯»å– JSON æ•°æ®
    logger.info(f"ğŸ“– è¯»å–æ•°æ®æ–‡ä»¶: {json_file}")
    with open(json_file, 'r', encoding='utf-8') as f:
        export_data = json.load(f)

    logger.info(f"ğŸ“Š å‘ç° {len(export_data)} ä¸ªè¡¨")

    # åˆ›å»º PostgreSQL è¿æ¥
    try:
        engine = create_engine(pg_connection_string, echo=False)
        Session = sessionmaker(bind=engine)
        session = Session()

        # æµ‹è¯•è¿æ¥
        session.execute(text("SELECT 1"))
        logger.info("âœ… PostgreSQL è¿æ¥æˆåŠŸ")

    except Exception as e:
        logger.error(f"âŒ æ— æ³•è¿æ¥åˆ° PostgreSQL: {e}")
        return False

    # è·å– PostgreSQL ä¸­çš„è¡¨ä¿¡æ¯
    inspector = inspect(engine)
    pg_tables = inspector.get_table_names()

    if not pg_tables:
        logger.error("âŒ PostgreSQL ä¸­æ²¡æœ‰è¡¨ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®åº“åˆå§‹åŒ–")
        logger.info("   æç¤º: python3 -c \"from app.models.database import init_db; init_db()\"")
        return False

    logger.info(f"ğŸ“‹ PostgreSQL ä¸­æœ‰ {len(pg_tables)} ä¸ªè¡¨")

    # å¯¼å…¥æ•°æ®
    total_imported = 0
    failed_tables = []

    try:
        for table_name, table_data in export_data.items():
            logger.info(f"\n  ğŸ“‹ æ­£åœ¨å¯¼å…¥è¡¨: {table_name}")

            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            if table_name not in pg_tables:
                logger.warning(f"    âš ï¸  è¡¨ {table_name} åœ¨ PostgreSQL ä¸­ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                failed_tables.append(table_name)
                continue

            rows = table_data['rows']
            columns = table_data['columns']

            if not rows:
                logger.info(f"    â„¹ï¸  è¡¨ {table_name} æ²¡æœ‰æ•°æ®ï¼Œè·³è¿‡")
                continue

            # æ¸…ç©ºç°æœ‰æ•°æ®ï¼ˆå¯é€‰ï¼‰
            # session.execute(text(f"TRUNCATE TABLE {table_name} CASCADE"))
            # logger.info(f"    ğŸ—‘ï¸  å·²æ¸…ç©ºè¡¨ {table_name}")

            # æ‰¹é‡æ’å…¥æ•°æ®
            imported_count = 0
            failed_count = 0

            for row in rows:
                try:
                    # æ„å»ºæ’å…¥è¯­å¥
                    col_names = ', '.join([f'"{col}"' for col in columns])
                    placeholders = ', '.join([f':{col}' for col in columns])
                    sql = f'INSERT INTO "{table_name}" ({col_names}) VALUES ({placeholders})'

                    # è½¬æ¢æ•°æ®ç±»å‹
                    row_data = {}
                    for col in columns:
                        value = row.get(col)
                        # å°è¯•è§£ææ—¥æœŸæ—¶é—´
                        if isinstance(value, str) and ('T' in value or 'created_at' in col or 'updated_at' in col or 'time' in col or 'date' in col):
                            value = parse_datetime(value)
                        row_data[col] = value

                    session.execute(text(sql), row_data)
                    imported_count += 1

                except Exception as e:
                    failed_count += 1
                    logger.debug(f"    âš ï¸  æ’å…¥å¤±è´¥: {e}")

            # æäº¤äº‹åŠ¡
            session.commit()

            total_imported += imported_count
            logger.info(f"    âœ… å¯¼å…¥ {imported_count} æ¡è®°å½•{f' (å¤±è´¥ {failed_count} æ¡)' if failed_count > 0 else ''}")

        # æ›´æ–°åºåˆ—ï¼ˆPostgreSQL è‡ªå¢ IDï¼‰
        logger.info("\nğŸ“Š æ›´æ–°è‡ªå¢åºåˆ—...")
        for table_name in pg_tables:
            try:
                # æŸ¥æ‰¾ä¸»é”®åˆ—
                pk_columns = inspector.get_pk_constraint(table_name)['constrained_columns']
                if pk_columns and len(pk_columns) == 1:
                    pk_col = pk_columns[0]

                    # è·å–æœ€å¤§ ID
                    result = session.execute(text(f'SELECT MAX("{pk_col}") FROM "{table_name}"'))
                    max_id = result.scalar()

                    if max_id:
                        # æ›´æ–°åºåˆ—
                        sequence_name = f'{table_name}_{pk_col}_seq'
                        session.execute(text(f"SELECT setval('{sequence_name}', {max_id})"))
                        logger.info(f"    âœ… æ›´æ–°åºåˆ— {sequence_name} -> {max_id}")

            except Exception as e:
                logger.debug(f"    âš ï¸  æ›´æ–°åºåˆ—å¤±è´¥ ({table_name}): {e}")

        session.commit()

        # æ˜¾ç¤ºå¯¼å…¥æ‘˜è¦
        logger.info("\n" + "=" * 60)
        logger.info("âœ… å¯¼å…¥å®Œæˆï¼")
        logger.info("=" * 60)
        logger.info(f"  ğŸ“Š æˆåŠŸå¯¼å…¥è¡¨æ•°: {len(export_data) - len(failed_tables)}")
        logger.info(f"  ğŸ“ æ€»è®°å½•æ•°: {total_imported}")
        if failed_tables:
            logger.warning(f"  âš ï¸  è·³è¿‡çš„è¡¨: {', '.join(failed_tables)}")
        logger.info("=" * 60)

        return True

    except Exception as e:
        logger.error(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        session.rollback()
        return False

    finally:
        session.close()


if __name__ == "__main__":
    # JSON æ•°æ®æ–‡ä»¶è·¯å¾„
    project_root = Path(__file__).parent.parent
    json_file = project_root / "data_export.json"

    # PostgreSQL è¿æ¥å­—ç¬¦ä¸²ï¼ˆä»ç¯å¢ƒå˜é‡æˆ–é…ç½®è¯»å–ï¼‰
    import sys
    sys.path.insert(0, str(project_root))

    # å°è¯•ä»é…ç½®è¯»å–
    try:
        from config.settings import get_settings
        settings = get_settings()
        pg_connection = settings.DATABASE_URL

        # æ£€æŸ¥æ˜¯å¦ä¸º PostgreSQL
        if not pg_connection.startswith('postgresql'):
            logger.error("âŒ é…ç½®ä¸­çš„ DATABASE_URL ä¸æ˜¯ PostgreSQL è¿æ¥å­—ç¬¦ä¸²")
            logger.info("   è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®:")
            logger.info("   DATABASE_URL=postgresql://user:password@localhost:5432/dbname")
            sys.exit(1)

    except Exception as e:
        logger.error(f"âŒ æ— æ³•è¯»å–é…ç½®: {e}")
        logger.info("   è¯·ç¡®ä¿ .env æ–‡ä»¶å­˜åœ¨å¹¶é…ç½®äº† DATABASE_URL")
        sys.exit(1)

    # æ‰§è¡Œå¯¼å…¥
    success = import_json_to_postgresql(str(json_file), pg_connection)

    if success:
        logger.info("\nğŸ‰ æ•°æ®å¯¼å…¥æˆåŠŸï¼")
        logger.info(f"   ä¸‹ä¸€æ­¥: è¿è¡Œ verify_migration.py éªŒè¯æ•°æ®ä¸€è‡´æ€§")
    else:
        logger.error("\nâŒ æ•°æ®å¯¼å…¥å¤±è´¥ï¼")
        sys.exit(1)

"""
å¤šçº§æ•°æ®åº“å¤‡ä»½è„šæœ¬
æ”¯æŒå°æ—¶çº§ã€å¤©çº§ã€å‘¨çº§å¤‡ä»½ï¼Œè‡ªåŠ¨æ¸…ç†æ—§å¤‡ä»½
"""
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import shutil
import subprocess
from pathlib import Path
from datetime import datetime, timedelta
import logging
from typing import Optional

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class DatabaseBackup:
    """æ•°æ®åº“å¤‡ä»½ç®¡ç†å™¨"""

    def __init__(self, project_root: Optional[Path] = None):
        """
        åˆå§‹åŒ–å¤‡ä»½ç®¡ç†å™¨

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
        """
        self.project_root = project_root or Path(__file__).parent.parent
        self.backup_dir = self.project_root / "backups"

        # åˆ›å»ºå¤‡ä»½ç›®å½•ç»“æ„
        self.hourly_dir = self.backup_dir / "hourly"
        self.daily_dir = self.backup_dir / "daily"
        self.weekly_dir = self.backup_dir / "weekly"

        for dir_path in [self.hourly_dir, self.daily_dir, self.weekly_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)

        # è¯»å–é…ç½®
        try:
            from config.settings import get_settings
            self.settings = get_settings()
            self.db_url = self.settings.DATABASE_URL
        except Exception as e:
            logger.error(f"âŒ æ— æ³•è¯»å–é…ç½®: {e}")
            self.db_url = None

    def is_postgresql(self) -> bool:
        """åˆ¤æ–­å½“å‰æ˜¯å¦ä½¿ç”¨ PostgreSQL"""
        return self.db_url and self.db_url.startswith('postgresql')

    def backup_sqlite(self, backup_path: Path) -> bool:
        """
        å¤‡ä»½ SQLite æ•°æ®åº“

        Args:
            backup_path: å¤‡ä»½æ–‡ä»¶è·¯å¾„

        Returns:
            bool: å¤‡ä»½æ˜¯å¦æˆåŠŸ
        """
        sqlite_db = self.project_root / "option_tracker.db"

        if not sqlite_db.exists():
            logger.error(f"âŒ SQLite æ•°æ®åº“ä¸å­˜åœ¨: {sqlite_db}")
            return False

        try:
            # ä½¿ç”¨ .backup å‘½ä»¤è¿›è¡Œçƒ­å¤‡ä»½
            import sqlite3
            conn = sqlite3.connect(str(sqlite_db))
            backup_conn = sqlite3.connect(str(backup_path))

            with backup_conn:
                conn.backup(backup_conn)

            conn.close()
            backup_conn.close()

            file_size = backup_path.stat().st_size / 1024
            logger.info(f"âœ… SQLite å¤‡ä»½æˆåŠŸ: {backup_path.name} ({file_size:.2f} KB)")
            return True

        except Exception as e:
            logger.error(f"âŒ SQLite å¤‡ä»½å¤±è´¥: {e}")
            return False

    def backup_postgresql(self, backup_path: Path) -> bool:
        """
        å¤‡ä»½ PostgreSQL æ•°æ®åº“

        Args:
            backup_path: å¤‡ä»½æ–‡ä»¶è·¯å¾„

        Returns:
            bool: å¤‡ä»½æ˜¯å¦æˆåŠŸ
        """
        if not self.db_url:
            logger.error("âŒ æ— æ³•è¯»å– DATABASE_URL")
            return False

        try:
            # è§£æè¿æ¥å­—ç¬¦ä¸²
            # postgresql://user:password@host:port/dbname
            from urllib.parse import urlparse
            parsed = urlparse(self.db_url)

            username = parsed.username
            password = parsed.password
            hostname = parsed.hostname
            port = parsed.port or 5432
            database = parsed.path.lstrip('/')

            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆé¿å…å¯†ç æç¤ºï¼‰
            env = os.environ.copy()
            env['PGPASSWORD'] = password

            # ä½¿ç”¨ pg_dump å¤‡ä»½
            cmd = [
                'pg_dump',
                '-h', hostname,
                '-p', str(port),
                '-U', username,
                '-F', 'c',  # custom format
                '-f', str(backup_path),
                database
            ]

            result = subprocess.run(
                cmd,
                env=env,
                capture_output=True,
                text=True,
                check=True
            )

            file_size = backup_path.stat().st_size / 1024
            logger.info(f"âœ… PostgreSQL å¤‡ä»½æˆåŠŸ: {backup_path.name} ({file_size:.2f} KB)")
            return True

        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ PostgreSQL å¤‡ä»½å¤±è´¥: {e.stderr}")
            return False
        except Exception as e:
            logger.error(f"âŒ PostgreSQL å¤‡ä»½å¤±è´¥: {e}")
            return False

    def create_backup(self, backup_type: str = "hourly") -> bool:
        """
        åˆ›å»ºå¤‡ä»½

        Args:
            backup_type: å¤‡ä»½ç±»å‹ (hourly/daily/weekly)

        Returns:
            bool: å¤‡ä»½æ˜¯å¦æˆåŠŸ
        """
        logger.info("=" * 60)
        logger.info(f"å¼€å§‹ {backup_type} å¤‡ä»½")
        logger.info("=" * 60)

        # ç¡®å®šå¤‡ä»½ç›®å½•
        if backup_type == "hourly":
            target_dir = self.hourly_dir
        elif backup_type == "daily":
            target_dir = self.daily_dir
        elif backup_type == "weekly":
            target_dir = self.weekly_dir
        else:
            logger.error(f"âŒ æœªçŸ¥çš„å¤‡ä»½ç±»å‹: {backup_type}")
            return False

        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

        if self.is_postgresql():
            backup_filename = f"pg_backup_{backup_type}_{timestamp}.dump"
            backup_path = target_dir / backup_filename
            success = self.backup_postgresql(backup_path)
        else:
            backup_filename = f"sqlite_backup_{backup_type}_{timestamp}.db"
            backup_path = target_dir / backup_filename
            success = self.backup_sqlite(backup_path)

        if success:
            # æ¸…ç†æ—§å¤‡ä»½
            self.cleanup_old_backups(backup_type)

        return success

    def cleanup_old_backups(self, backup_type: str):
        """
        æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶

        Args:
            backup_type: å¤‡ä»½ç±»å‹ (hourly/daily/weekly)
        """
        # ç¡®å®šä¿ç•™ç­–ç•¥
        if backup_type == "hourly":
            target_dir = self.hourly_dir
            keep_count = 24  # ä¿ç•™æœ€è¿‘ 24 å°æ—¶
            max_age_days = 7  # è¶…è¿‡ 7 å¤©çš„ç›´æ¥åˆ é™¤
        elif backup_type == "daily":
            target_dir = self.daily_dir
            keep_count = 30  # ä¿ç•™æœ€è¿‘ 30 å¤©
            max_age_days = 90  # è¶…è¿‡ 90 å¤©çš„ç›´æ¥åˆ é™¤
        elif backup_type == "weekly":
            target_dir = self.weekly_dir
            keep_count = 12  # ä¿ç•™æœ€è¿‘ 12 å‘¨
            max_age_days = 365  # è¶…è¿‡ 1 å¹´çš„ç›´æ¥åˆ é™¤
        else:
            return

        try:
            # è·å–æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
            if self.is_postgresql():
                pattern = f"pg_backup_{backup_type}_*.dump"
            else:
                pattern = f"sqlite_backup_{backup_type}_*.db"

            backup_files = sorted(
                target_dir.glob(pattern),
                key=lambda f: f.stat().st_mtime,
                reverse=True
            )

            # åˆ é™¤è¶…è¿‡æœ€å¤§å¹´é¾„çš„æ–‡ä»¶
            cutoff_time = datetime.now() - timedelta(days=max_age_days)
            deleted_old = 0

            for backup_file in backup_files:
                file_time = datetime.fromtimestamp(backup_file.stat().st_mtime)
                if file_time < cutoff_time:
                    backup_file.unlink()
                    deleted_old += 1

            # åªä¿ç•™æœ€æ–°çš„ N ä¸ªæ–‡ä»¶
            if len(backup_files) > keep_count:
                for backup_file in backup_files[keep_count:]:
                    if backup_file.exists():  # å¯èƒ½å·²ç»è¢«ä¸Šé¢åˆ é™¤
                        backup_file.unlink()

            deleted_excess = max(0, len(backup_files) - keep_count - deleted_old)

            if deleted_old > 0 or deleted_excess > 0:
                logger.info(f"ğŸ—‘ï¸  æ¸…ç†æ—§å¤‡ä»½: åˆ é™¤ {deleted_old + deleted_excess} ä¸ªæ–‡ä»¶")
                logger.info(f"   ä¿ç•™æœ€æ–° {min(keep_count, len(backup_files))} ä¸ªå¤‡ä»½")

        except Exception as e:
            logger.warning(f"âš ï¸  æ¸…ç†æ—§å¤‡ä»½å¤±è´¥: {e}")

    def list_backups(self):
        """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½æ–‡ä»¶"""
        logger.info("=" * 60)
        logger.info("å¤‡ä»½æ–‡ä»¶åˆ—è¡¨")
        logger.info("=" * 60)

        for backup_type, target_dir in [
            ("hourly", self.hourly_dir),
            ("daily", self.daily_dir),
            ("weekly", self.weekly_dir)
        ]:
            backup_files = sorted(
                target_dir.glob("*"),
                key=lambda f: f.stat().st_mtime,
                reverse=True
            )

            logger.info(f"\nğŸ“ {backup_type.capitalize()} å¤‡ä»½ ({len(backup_files)} ä¸ª):")

            if not backup_files:
                logger.info("   (æ— å¤‡ä»½æ–‡ä»¶)")
                continue

            for backup_file in backup_files[:5]:  # åªæ˜¾ç¤ºæœ€æ–° 5 ä¸ª
                file_time = datetime.fromtimestamp(backup_file.stat().st_mtime)
                file_size = backup_file.stat().st_size / 1024
                logger.info(f"   - {backup_file.name}")
                logger.info(f"     æ—¶é—´: {file_time.strftime('%Y-%m-%d %H:%M:%S')}")
                logger.info(f"     å¤§å°: {file_size:.2f} KB")

            if len(backup_files) > 5:
                logger.info(f"   ... è¿˜æœ‰ {len(backup_files) - 5} ä¸ªå¤‡ä»½")

    def restore_backup(self, backup_file: Path) -> bool:
        """
        æ¢å¤å¤‡ä»½

        Args:
            backup_file: å¤‡ä»½æ–‡ä»¶è·¯å¾„

        Returns:
            bool: æ¢å¤æ˜¯å¦æˆåŠŸ
        """
        logger.info("=" * 60)
        logger.info(f"å¼€å§‹æ¢å¤å¤‡ä»½: {backup_file.name}")
        logger.info("=" * 60)

        if not backup_file.exists():
            logger.error(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_file}")
            return False

        # æ ¹æ®æ–‡ä»¶æ‰©å±•ååˆ¤æ–­å¤‡ä»½ç±»å‹
        if backup_file.suffix == '.db':
            return self._restore_sqlite(backup_file)
        elif backup_file.suffix == '.dump':
            return self._restore_postgresql(backup_file)
        else:
            logger.error(f"âŒ æœªçŸ¥çš„å¤‡ä»½æ–‡ä»¶ç±»å‹: {backup_file.suffix}")
            return False

    def _restore_sqlite(self, backup_file: Path) -> bool:
        """æ¢å¤ SQLite å¤‡ä»½"""
        sqlite_db = self.project_root / "option_tracker.db"

        try:
            # å¤‡ä»½å½“å‰æ•°æ®åº“
            if sqlite_db.exists():
                current_backup = self.project_root / f"option_tracker.db.before_restore_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                shutil.copy2(sqlite_db, current_backup)
                logger.info(f"âœ… å½“å‰æ•°æ®åº“å·²å¤‡ä»½è‡³: {current_backup.name}")

            # æ¢å¤å¤‡ä»½
            shutil.copy2(backup_file, sqlite_db)
            logger.info(f"âœ… SQLite æ•°æ®åº“æ¢å¤æˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"âŒ SQLite æ¢å¤å¤±è´¥: {e}")
            return False

    def _restore_postgresql(self, backup_file: Path) -> bool:
        """æ¢å¤ PostgreSQL å¤‡ä»½"""
        if not self.db_url:
            logger.error("âŒ æ— æ³•è¯»å– DATABASE_URL")
            return False

        try:
            from urllib.parse import urlparse
            parsed = urlparse(self.db_url)

            username = parsed.username
            password = parsed.password
            hostname = parsed.hostname
            port = parsed.port or 5432
            database = parsed.path.lstrip('/')

            # è®¾ç½®ç¯å¢ƒå˜é‡
            env = os.environ.copy()
            env['PGPASSWORD'] = password

            # ä½¿ç”¨ pg_restore æ¢å¤
            cmd = [
                'pg_restore',
                '-h', hostname,
                '-p', str(port),
                '-U', username,
                '-d', database,
                '-c',  # æ¸…ç©ºç°æœ‰æ•°æ®
                str(backup_file)
            ]

            result = subprocess.run(
                cmd,
                env=env,
                capture_output=True,
                text=True,
                check=True
            )

            logger.info(f"âœ… PostgreSQL æ•°æ®åº“æ¢å¤æˆåŠŸ")
            return True

        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ PostgreSQL æ¢å¤å¤±è´¥: {e.stderr}")
            return False
        except Exception as e:
            logger.error(f"âŒ PostgreSQL æ¢å¤å¤±è´¥: {e}")
            return False


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='æ•°æ®åº“å¤‡ä»½ç®¡ç†')
    parser.add_argument('action', choices=['backup', 'list', 'restore'],
                        help='æ“ä½œç±»å‹: backup(åˆ›å»ºå¤‡ä»½)/list(åˆ—å‡ºå¤‡ä»½)/restore(æ¢å¤å¤‡ä»½)')
    parser.add_argument('--type', choices=['hourly', 'daily', 'weekly'],
                        default='daily', help='å¤‡ä»½ç±»å‹ï¼ˆä»…ç”¨äº backupï¼‰')
    parser.add_argument('--file', type=str, help='å¤‡ä»½æ–‡ä»¶è·¯å¾„ï¼ˆä»…ç”¨äº restoreï¼‰')

    args = parser.parse_args()

    backup_manager = DatabaseBackup()

    if args.action == 'backup':
        success = backup_manager.create_backup(args.type)
        if success:
            logger.info(f"\nâœ… {args.type} å¤‡ä»½åˆ›å»ºæˆåŠŸ")
            sys.exit(0)
        else:
            logger.error(f"\nâŒ {args.type} å¤‡ä»½åˆ›å»ºå¤±è´¥")
            sys.exit(1)

    elif args.action == 'list':
        backup_manager.list_backups()

    elif args.action == 'restore':
        if not args.file:
            logger.error("âŒ è¯·ä½¿ç”¨ --file æŒ‡å®šè¦æ¢å¤çš„å¤‡ä»½æ–‡ä»¶")
            sys.exit(1)

        backup_file = Path(args.file)
        success = backup_manager.restore_backup(backup_file)

        if success:
            logger.info("\nâœ… æ•°æ®åº“æ¢å¤æˆåŠŸ")
            sys.exit(0)
        else:
            logger.error("\nâŒ æ•°æ®åº“æ¢å¤å¤±è´¥")
            sys.exit(1)

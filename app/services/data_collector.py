"""
æ•°æ®é‡‡é›†è£…é¥°å™¨
è‡ªåŠ¨è®°å½•æ•°æ®é‡‡é›†æ—¥å¿—å’Œè´¨é‡æŒ‡æ ‡ï¼Œæ”¯æŒé‡è¯•å’Œå‘Šè­¦
"""
from functools import wraps
from datetime import datetime
import time
import traceback
import asyncio
import logging
from typing import Callable, Any, List, Dict, Optional
from app.models.database import SessionLocal
from app.models.data_governance import DataSource, DataCollectionLog, DataQualityMetric

logger = logging.getLogger(__name__)


def send_feishu_alert(title: str, content: str, webhook_url: Optional[str] = None):
    """
    å‘é€é£ä¹¦å‘Šè­¦é€šçŸ¥

    Args:
        title: å‘Šè­¦æ ‡é¢˜
        content: å‘Šè­¦å†…å®¹
        webhook_url: é£ä¹¦æœºå™¨äººwebhookåœ°å€ï¼ˆå¯é€‰ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
    """
    try:
        import requests
        from config.settings import get_settings

        settings = get_settings()
        webhook = webhook_url or getattr(settings, 'FEISHU_WEBHOOK', None)

        if not webhook:
            logger.warning("æœªé…ç½®é£ä¹¦webhookï¼Œè·³è¿‡å‘Šè­¦å‘é€")
            return

        # é£ä¹¦å¯Œæ–‡æœ¬æ¶ˆæ¯æ ¼å¼
        message = {
            "msg_type": "interactive",
            "card": {
                "config": {
                    "wide_screen_mode": True
                },
                "header": {
                    "title": {
                        "tag": "plain_text",
                        "content": title
                    },
                    "template": "red"  # çº¢è‰²è¡¨ç¤ºå‘Šè­¦
                },
                "elements": [
                    {
                        "tag": "div",
                        "text": {
                            "tag": "lark_md",
                            "content": content
                        }
                    },
                    {
                        "tag": "hr"
                    },
                    {
                        "tag": "div",
                        "text": {
                            "tag": "lark_md",
                            "content": f"ğŸ“… **å‘é€æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                        }
                    }
                ]
            }
        }

        response = requests.post(webhook, json=message, timeout=5)
        if response.status_code == 200:
            result = response.json()
            if result.get('StatusCode') == 0:
                logger.info(f"âœ… é£ä¹¦å‘Šè­¦å‘é€æˆåŠŸ: {title}")
            else:
                logger.error(f"âŒ é£ä¹¦å‘Šè­¦å‘é€å¤±è´¥: {result.get('msg')}")
        else:
            logger.error(f"âŒ é£ä¹¦å‘Šè­¦å‘é€å¤±è´¥: HTTP {response.status_code}")

    except Exception as e:
        logger.error(f"å‘é€é£ä¹¦å‘Šè­¦å¼‚å¸¸: {e}")


class DataCollector:
    """
    æ•°æ®é‡‡é›†è£…é¥°å™¨ - è‡ªåŠ¨è®°å½•é‡‡é›†æ—¥å¿—ã€é‡è¯•ã€å‘Šè­¦

    åŠŸèƒ½ï¼š
    1. è‡ªåŠ¨è®°å½•é‡‡é›†æ—¥å¿—åˆ°æ•°æ®åº“
    2. å¤±è´¥è‡ªåŠ¨é‡è¯•ï¼ˆå¯é…ç½®æ¬¡æ•°å’Œé—´éš”ï¼‰
    3. æœ€ç»ˆå¤±è´¥å‘é€é’‰é’‰å‘Šè­¦
    4. æ•°æ®è´¨é‡è¯„åˆ†
    5. æ›´æ–°æ•°æ®æºå¥åº·çŠ¶æ€
    """

    def __init__(
        self,
        source_name: str,
        calculate_quality: bool = True,
        max_retries: int = 3,
        retry_delay: int = 60,
        timeout: int = 300,
        enable_alert: bool = True
    ):
        """
        Args:
            source_name: æ•°æ®æºåç§°
            calculate_quality: æ˜¯å¦è®¡ç®—æ•°æ®è´¨é‡
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            retry_delay: é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            enable_alert: æ˜¯å¦å¯ç”¨é’‰é’‰å‘Šè­¦
        """
        self.source_name = source_name
        self.calculate_quality = calculate_quality
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        self.timeout = timeout
        self.enable_alert = enable_alert

    def __call__(self, func: Callable) -> Callable:
        # æ£€æµ‹å‡½æ•°æ˜¯å¦ä¸ºasync
        is_async = asyncio.iscoroutinefunction(func)

        if is_async:
            @wraps(func)
            async def async_wrapper(*args, **kwargs):
                return await self._execute_with_retry_async(func, args, kwargs)
            return async_wrapper
        else:
            @wraps(func)
            def sync_wrapper(*args, **kwargs):
                return self._execute_with_retry_sync(func, args, kwargs)
            return sync_wrapper

    async def _execute_with_retry_async(self, func: Callable, args: tuple, kwargs: dict):
        """å¼‚æ­¥å‡½æ•°é‡è¯•é€»è¾‘"""
        last_exception = None

        for attempt in range(self.max_retries + 1):
            try:
                if attempt > 0:
                    logger.info(f"[{self.source_name}] ç¬¬ {attempt}/{self.max_retries} æ¬¡é‡è¯•...")
                    await asyncio.sleep(self.retry_delay)

                # æ‰§è¡Œé‡‡é›†
                result = await self._execute_single_attempt_async(func, args, kwargs, attempt + 1)
                return result

            except Exception as e:
                last_exception = e
                logger.error(f"[{self.source_name}] ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")

                if attempt < self.max_retries:
                    continue
                else:
                    # æœ€ç»ˆå¤±è´¥ï¼Œå‘é€å‘Šè­¦
                    if self.enable_alert:
                        self._send_failure_alert(e, attempt + 1)
                    raise

        raise last_exception

    def _execute_with_retry_sync(self, func: Callable, args: tuple, kwargs: dict):
        """åŒæ­¥å‡½æ•°é‡è¯•é€»è¾‘"""
        last_exception = None

        for attempt in range(self.max_retries + 1):
            try:
                if attempt > 0:
                    logger.info(f"[{self.source_name}] ç¬¬ {attempt}/{self.max_retries} æ¬¡é‡è¯•...")
                    time.sleep(self.retry_delay)

                # æ‰§è¡Œé‡‡é›†
                result = self._execute_single_attempt_sync(func, args, kwargs, attempt + 1)
                return result

            except Exception as e:
                last_exception = e
                logger.error(f"[{self.source_name}] ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}")

                if attempt < self.max_retries:
                    continue
                else:
                    # æœ€ç»ˆå¤±è´¥ï¼Œå‘é€å‘Šè­¦
                    if self.enable_alert:
                        self._send_failure_alert(e, attempt + 1)
                    raise

        raise last_exception

    async def _execute_single_attempt_async(self, func: Callable, args: tuple, kwargs: dict, attempt_num: int):
        """æ‰§è¡Œå•æ¬¡å¼‚æ­¥é‡‡é›†å°è¯•"""
        db = SessionLocal()
        start_time = time.time()
        collect_time = datetime.now()

        # è·å–æ•°æ®æºID
        source = db.query(DataSource).filter_by(source_name=self.source_name).first()
        if not source:
            logger.warning(f"âš ï¸ æ•°æ®æºæœªæ³¨å†Œ: {self.source_name}")
            db.close()
            return await func(*args, **kwargs)

        source_id = source.id

        try:
            # æ‰§è¡Œé‡‡é›†ï¼ˆæ”¯æŒè¶…æ—¶ï¼‰
            result = await asyncio.wait_for(
                func(*args, **kwargs),
                timeout=self.timeout
            )

            duration = int(time.time() - start_time)

            # åˆ†æç»“æœ
            records_collected = self._count_records(result)
            quality_score, missing_rate = self._calculate_quality(result) if self.calculate_quality else (None, None)

            # è®°å½•æˆåŠŸæ—¥å¿—
            log = DataCollectionLog(
                source_id=source_id,
                source_name=self.source_name,
                collect_time=collect_time,
                status='success',
                duration_seconds=duration,
                records_collected=records_collected,
                records_inserted=records_collected,
                data_quality_score=quality_score,
                missing_rate=missing_rate
            )
            db.add(log)

            # æ›´æ–°æ•°æ®æºçŠ¶æ€
            source.last_collect_time = collect_time
            source.last_collect_status = 'success'
            source.last_record_count = records_collected
            source.health_status = 'healthy' if quality_score is None or quality_score >= 80 else 'warning'

            db.commit()

            logger.info(f"âœ… [{self.source_name}] é‡‡é›†æˆåŠŸ: {records_collected}æ¡æ•°æ®ï¼Œè€—æ—¶{duration}ç§’")

            return result

        except Exception as e:
            duration = int(time.time() - start_time)
            error_msg = str(e)
            error_trace = traceback.format_exc()

            # è®°å½•å¤±è´¥æ—¥å¿—
            log = DataCollectionLog(
                source_id=source_id,
                source_name=self.source_name,
                collect_time=collect_time,
                status='failed',
                duration_seconds=duration,
                records_collected=0,
                error_message=error_msg,
                error_traceback=error_trace
            )
            db.add(log)

            # æ›´æ–°æ•°æ®æºçŠ¶æ€
            source.last_collect_time = collect_time
            source.last_collect_status = 'failed'
            source.health_status = 'critical'

            db.commit()

            logger.error(f"âŒ [{self.source_name}] é‡‡é›†å¤±è´¥: {error_msg}")

            raise

        finally:
            db.close()

    def _execute_single_attempt_sync(self, func: Callable, args: tuple, kwargs: dict, attempt_num: int):
        """æ‰§è¡Œå•æ¬¡åŒæ­¥é‡‡é›†å°è¯•"""
        db = SessionLocal()
        start_time = time.time()
        collect_time = datetime.now()

        # è·å–æ•°æ®æºID
        source = db.query(DataSource).filter_by(source_name=self.source_name).first()
        if not source:
            logger.warning(f"âš ï¸ æ•°æ®æºæœªæ³¨å†Œ: {self.source_name}")
            db.close()
            return func(*args, **kwargs)

        source_id = source.id

        try:
            # æ‰§è¡Œé‡‡é›†
            result = func(*args, **kwargs)

            duration = int(time.time() - start_time)

            # åˆ†æç»“æœ
            records_collected = self._count_records(result)
            quality_score, missing_rate = self._calculate_quality(result) if self.calculate_quality else (None, None)

            # è®°å½•æˆåŠŸæ—¥å¿—
            log = DataCollectionLog(
                source_id=source_id,
                source_name=self.source_name,
                collect_time=collect_time,
                status='success',
                duration_seconds=duration,
                records_collected=records_collected,
                records_inserted=records_collected,
                data_quality_score=quality_score,
                missing_rate=missing_rate
            )
            db.add(log)

            # æ›´æ–°æ•°æ®æºçŠ¶æ€
            source.last_collect_time = collect_time
            source.last_collect_status = 'success'
            source.last_record_count = records_collected
            source.health_status = 'healthy' if quality_score is None or quality_score >= 80 else 'warning'

            db.commit()

            logger.info(f"âœ… [{self.source_name}] é‡‡é›†æˆåŠŸ: {records_collected}æ¡æ•°æ®ï¼Œè€—æ—¶{duration}ç§’")

            return result

        except Exception as e:
            duration = int(time.time() - start_time)
            error_msg = str(e)
            error_trace = traceback.format_exc()

            # è®°å½•å¤±è´¥æ—¥å¿—
            log = DataCollectionLog(
                source_id=source_id,
                source_name=self.source_name,
                collect_time=collect_time,
                status='failed',
                duration_seconds=duration,
                records_collected=0,
                error_message=error_msg,
                error_traceback=error_trace
            )
            db.add(log)

            # æ›´æ–°æ•°æ®æºçŠ¶æ€
            source.last_collect_time = collect_time
            source.last_collect_status = 'failed'
            source.health_status = 'critical'

            db.commit()

            logger.error(f"âŒ [{self.source_name}] é‡‡é›†å¤±è´¥: {error_msg}")

            raise

        finally:
            db.close()

    def _send_failure_alert(self, exception: Exception, total_attempts: int):
        """å‘é€å¤±è´¥å‘Šè­¦"""
        title = f"ğŸš¨ æ•°æ®é‡‡é›†å¤±è´¥å‘Šè­¦ - {self.source_name}"
        content = f"""**æ•°æ®æº**: {self.source_name}

**çŠ¶æ€**: âŒ é‡‡é›†å¤±è´¥

**é‡è¯•æ¬¡æ•°**: {total_attempts} æ¬¡

**é”™è¯¯ä¿¡æ¯**:
```
{str(exception)}
```

**æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

è¯·åŠæ—¶æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—å¹¶å¤„ç†ï¼"""
        send_feishu_alert(title, content)

    def _count_records(self, result: Any) -> int:
        """ç»Ÿè®¡è®°å½•æ•°"""
        if result is None:
            return 0
        if isinstance(result, list):
            return len(result)
        if isinstance(result, dict):
            return len(result)
        return 1

    def _calculate_quality(self, result: Any) -> tuple:
        """è®¡ç®—æ•°æ®è´¨é‡è¯„åˆ†"""
        if not result:
            return 0.0, 100.0

        try:
            if isinstance(result, list) and len(result) > 0:
                # æ£€æŸ¥ç¼ºå¤±å€¼
                total_fields = 0
                missing_fields = 0

                for item in result[:100]:  # é‡‡æ ·å‰100æ¡
                    if isinstance(item, dict):
                        total_fields += len(item)
                        missing_fields += sum(1 for v in item.values() if v is None or v == '')

                missing_rate = (missing_fields / total_fields * 100) if total_fields > 0 else 0
                quality_score = max(0, 100 - missing_rate)

                return quality_score, missing_rate

        except Exception as e:
            print(f"è´¨é‡è®¡ç®—å¼‚å¸¸: {e}")

        return None, None


def register_data_source(
    source_name: str,
    source_type: str,
    category: str,
    provider: str,
    url: str = None,
    description: str = None,
    update_frequency: str = "daily",
    cron_expression: str = None,
    data_fields: List[str] = None,
    dependencies: List[str] = None
):
    """
    æ³¨å†Œæ•°æ®æº

    Args:
        source_name: æ•°æ®æºåç§°ï¼ˆå”¯ä¸€ï¼‰
        source_type: ç±»å‹ - api/spider/file/service
        category: åˆ†ç±» - fundamental/technical/capital/news
        provider: æä¾›æ–¹ - akshare/æ™ºæ±‡æœŸè®¯/ç™¾åº¦OCRç­‰
        url: æ•°æ®URLæˆ–APIåœ°å€
        description: è¯´æ˜
        update_frequency: æ›´æ–°é¢‘ç‡ - realtime/hourly/daily/weekly
        cron_expression: Cronè¡¨è¾¾å¼
        data_fields: æ•°æ®å­—æ®µåˆ—è¡¨
        dependencies: ä¾èµ–çš„å…¶ä»–æ•°æ®æº
    """
    db = SessionLocal()
    try:
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing = db.query(DataSource).filter_by(source_name=source_name).first()
        if existing:
            print(f"âš ï¸ æ•°æ®æºå·²å­˜åœ¨: {source_name}")
            return existing

        # åˆ›å»ºæ–°æ•°æ®æº
        source = DataSource(
            source_name=source_name,
            source_type=source_type,
            category=category,
            provider=provider,
            url=url,
            description=description,
            update_frequency=update_frequency,
            cron_expression=cron_expression,
            data_fields=data_fields,
            dependencies=dependencies
        )

        db.add(source)
        db.commit()
        db.refresh(source)

        print(f"âœ… æ•°æ®æºæ³¨å†ŒæˆåŠŸ: {source_name}")
        return source

    finally:
        db.close()
